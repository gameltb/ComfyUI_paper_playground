# ComfyUI paper playground

Evaluate some papers in ComfyUI, just playground.

# Play

First of all, this is a very experimental repo, and a lot of APIs or nodes may change in the future.

[node list](node.md) (Automatically generated by annotation)

> [!NOTE]
>
> The diffusers series nodes do not currently consider the object cache, and after modifying the workflow with the node modifying the pipeline object, you need to re-execute the node that generated the pipeline object to ensure that it is correct.

## Create your node

This repo use decorator to create and register the node.  
You can put the node file under the `module/comfy/node/` folder , paper repo to `module/paper/`.  
Than import you node at [module/comfy/\_\_init\_\_.py](module/comfy/__init__.py).  
example node

```python
import os
from typing import Annotated, Optional

from ..registry import register_node
from ..types import (
    BoolType,
    ComboWidget,
    ComfyWidgetType,
    StringWidget,
    gen_widget,
    new_widget,
)  # some base comfyui type


class ExampleWidget(ComfyWidgetType):
    TYPE = "EXAMPLE"  # identifier of comfyui type.


ExampleType = Annotated[bool, ExampleWidget()]  # TypeAlias , use as bool

SimpleType = Annotated[str, gen_widget("SIMPLE")]  # Simple TypeAlias without definition Widget, use as str
"""Simple type doc"""


@register_node(
    identifier="node_identifier",  # identifier of node. If not provided, it will be generated from the function name.
    display_name="display_name",  # display_name show to user. it will be generated from the identifier.
    category="loaders",  # category under playground.
)
def example(
    widget_input1: StringWidget(),  # use widget instance as type hint , register_node will convert it to an inputType. but it is not valid for programmers.
    input1: ExampleType,  # use Annotated type , This is the recommended way.
    input2: BoolType = True,  # you can set default value.
    op_input1: Annotated[BoolType, new_widget(BoolType, is_required=False)] = True,  # change widget property,
    combo_input0: Annotated[
        str, ComboWidget(choices=["int"])
    ] = None,  # use Combo widget to select an item from the list.
    combo_input1: Annotated[
        type, ComboWidget(choices={"int": int})
    ] = None,  # with dict choices Combo widget will automatically convert  key to value .
    combo_input2: Annotated[
        str, ComboWidget(choices=lambda: os.listdir("."))
    ] = None,  # with lambda Combo widget will update list when web page refresh.
    combo_input3: Annotated[
        Optional[type], ComboWidget(choices=lambda: {"int": int}, ext_none_choice="none")
    ] = None,  # you can set an extra None option name, which is converted to None when passed in.
) -> tuple[ExampleType, SimpleType]:  # return type
    """example node description."""
    # do what you want.
    pass
```

## IP-Adapter

Put https://huggingface.co/h94/IP-Adapter to `ComfyUI/models/diffusers/IP-Adapter`.

# Paper

## [PIAï¼šPersonalized Image Animator](https://github.com/open-mmlab/PIA)

Put PIA Checkpoint to `ComfyUI/models/playground/paper/arxiv/abs2312_13964/pia/pia.ckpt`.  
Put https://huggingface.co/runwayml/stable-diffusion-v1-5 to `ComfyUI/models/diffusers/stable-diffusion-v1-5`.  
Put majicmixRealistic(https://civitai.com/models/43331) model to `ComfyUI/models/checkpoints/`.

## [Marigold: Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation](https://github.com/prs-eth/Marigold)

Put https://huggingface.co/Bingxin/Marigold to `ComfyUI/models/diffusers/Marigold`.

## [HybrIK: Hybrid Analytical-Neural Inverse Kinematics for Body Mesh Recovery](https://github.com/Jeff-sjtu/HybrIK)

Refer to the README.

```bash
pip install "git+https://github.com/facebookresearch/pytorch3d.git"
```

Unzip model_files to directory `ComfyUI/models/playground/paper/arxiv/abs2304_05690/` .  
Put HybrIK-X rle model to `ComfyUI/models/playground/paper/arxiv/abs2304_05690/hybrikx/`.

Get smplx_blender_addon_300_20220623.zip from https://smpl-x.is.tue.mpg.de/.
Use blender load /smplx_blender_addon/data/smplx_model_300_20220615.blend file in zip.  
Use [blender_frame_import.py](module/paper/arxiv/abs2304_05690/blender_frame_import.py) to load frame.

## [LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation](https://github.com/3DTopia/LGM)

Refer to the README.

```bash
git clone --recursive https://github.com/ashawkey/diff-gaussian-rasterization
pip install ./diff-gaussian-rasterization
```

Put model.safetensors in https://huggingface.co/ashawkey/LGM to `ComfyUI/models/playground/paper/arxiv/abs2402_05054`

## [PeRFlow: Piecewise Rectified Flow as Universal Plug-and-Play Accelerator](https://github.com/magic-research/piecewise-rectified-flow)

Put https://huggingface.co/hansyan/perflow-sd15-delta-weights to `ComfyUI/models/diffusers/perflow-sd15-delta-weights`.  
Use `Apply Piecewise Rectified Flow` node.

## [DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors](https://github.com/Doubiiu/DynamiCrafter)

Put https://huggingface.co/Doubiiu/DynamiCrafter_512_Interp/blob/main/model.ckpt to `ComfyUI/models/playground/paper/arxiv/abs2310_12190/`.

## [OMS-Diffusion: One More Step Diffusion is All You Need for Virtual Try-on](https://github.com/ShineChen1024/oms-Diffusion)

Put model in https://huggingface.co/shinehugging/oms-diffusion to `ComfyUI/models/playground/paper/arxiv/abs2403_01779/`.

# github

## [JoyTag](https://github.com/fpgaminer/joytag)

JoyTag is a state of the art AI vision model for tagging images.

Put https://huggingface.co/fancyfeast/joytag to `ComfyUI/models/playground/paper/github/joytag`
